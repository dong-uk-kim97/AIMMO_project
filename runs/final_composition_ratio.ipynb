{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "128dcd0b",
      "metadata": {
        "id": "128dcd0b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv('/home/kdw24739577/df_train.csv', index_col = 0)\n",
        "df_val = pd.read_csv('/home/kdw24739577/df_val.csv', index_col = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea3d7551",
      "metadata": {
        "id": "ea3d7551"
      },
      "outputs": [],
      "source": [
        "# 주:야 = 50:50\n",
        "# 맑:흐:비 = 60:30:10\n",
        "# '데이터 구성비 목록' 노션페이지에 있는 장수 보고 n만 바꿔줌\n",
        "df_1 = df_train[(df_train['time'] == 'day')&(df_train['weather'] == 'sunny')].sample(n=18326, random_state=2022)\n",
        "df_2 = df_train[(df_train['time'] == 'day')&(df_train['weather'] == 'cloudy')].sample(n=10233, random_state=2022)\n",
        "df_3 = df_train[(df_train['time'] == 'day')&(df_train['weather'] == 'rain')].sample(n=5377, random_state=2022)\n",
        "df_4 = df_train[((df_train['time'] == 'sunset')|(df_train['time'] == 'night'))&(df_train['weather'] == 'sunny')].sample(n=11870, random_state=2022)\n",
        "df_5 = df_train[((df_train['time'] == 'sunset')|(df_train['time'] == 'night'))&(df_train['weather'] == 'cloudy')].sample(n=6996, random_state=2022)\n",
        "df_6 = df_train[((df_train['time'] == 'sunset')|(df_train['time'] == 'night'))&(df_train['weather'] == 'rain')].sample(n=3758, random_state=2022)\n",
        "df_train_use = pd.concat([df_1,df_2,df_3,df_4,df_5,df_6])\n",
        "train_img_list = df_train_use['train_path'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca3ed79",
      "metadata": {
        "id": "6ca3ed79"
      },
      "outputs": [],
      "source": [
        "# df_train_use.csv 본인 실험 runs 폴더에 업로드\n",
        "df_train_use.to_csv('/home/kdw24739577/df_train_use_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb436887",
      "metadata": {
        "id": "fb436887",
        "outputId": "0202b5f3-2145-462d-9c07-582b068ecea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "56560 7808\n",
            "(70153, 45) (7808, 44)\n"
          ]
        }
      ],
      "source": [
        "# 전체 데이터로 train_datasets 구성\n",
        "# train_img_list = df_train['train_path'].to_list()\n",
        "val_img_list = df_val['val_path'].to_list()\n",
        "\n",
        "# 특정 조건별 train_datasets 구성\n",
        "# train_img_list = df_train[df_train['weather']=='sunny']['train_path'].to_list()\n",
        "# val_img_list = df_val['val_path'].to_list()\n",
        "# test_img_list = glob('/aiffel/aiffel/datasets/images/train/*.png') test 파일을 정하지 않았기 때문에 주석 처리 임의로 정하면 다시 수정\n",
        "print(len(train_img_list), len(val_img_list))\n",
        "print(df_train.shape, df_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59778827",
      "metadata": {
        "id": "59778827"
      },
      "outputs": [],
      "source": [
        "with open('/home/kdw24739577/datasets/train.txt', 'w') as f: # train.txt에 파일 경로를 전부 적어줌 \n",
        "  f.write('\\n'.join(train_img_list)+'\\n')\n",
        "with open('/home/kdw24739577/datasets/val.txt', 'w') as f: # val.txt에 파일 경로를 전부 적어줌\n",
        "  f.write('\\n'.join(val_img_list)+'\\n')\n",
        "# with open('/aiffel/aiffel/datasets/test.txt', 'w') as f:\n",
        "#   f.write('\\n'.join(test_img_list)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddb1027a",
      "metadata": {
        "id": "ddb1027a",
        "outputId": "a9f951db-b42c-40ff-f772-7a77c8ad3438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: wandb 0.13.6\n",
            "Uninstalling wandb-0.13.6:\n",
            "  Successfully uninstalled wandb-0.13.6\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall -y wandb\n",
        "# !pip install wandb\n",
        "\n",
        "# import wandb\n",
        "\n",
        "# wandb.login()\n",
        "# 본인 wandb 키값넣기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c20edc1",
      "metadata": {
        "id": "2c20edc1",
        "outputId": "caa04546-2968-445b-fd0c-313eb19ee470"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c2b756",
      "metadata": {
        "scrolled": false,
        "id": "94c2b756",
        "outputId": "72e10fbf-feb8-4c8a-9369-d9a07f53f600"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/kdw24739577/yolov5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=./runs/train/DR_all_epochs_404/weights/last.pt, cfg=, data=/home/kdw24739577/yolov5/data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=40, batch_size=32, imgsz=960, rect=True, resume=True, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=DR_all_epochs40, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=300, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 28 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 🚀 v6.2-267-gbe348cc Python-3.9.13 torch-1.7.1+cu110 CUDA:0 (Tesla V100-SXM2-16GB, 16161MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.35, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n",
            "  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n",
            "  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n",
            "  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n",
            "  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n",
            "  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n",
            "  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n",
            "  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n",
            "  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n",
            "  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n",
            " 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n",
            " 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n",
            " 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n",
            " 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n",
            " 24      [17, 20, 23]  1     36369  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n",
            "Model summary: 291 layers, 20883441 parameters, 20883441 gradients, 48.3 GFLOPs\n",
            "\n",
            "Transferred 481/481 items from runs/train/DR_all_epochs404/weights/last.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\n",
            "Resuming training from runs/train/DR_all_epochs404/weights/last.pt from epoch 3 to 40 total epochs\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/kdw24739577/datasets/train.cache... 56560 images, 0 backgr\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/kdw24739577/datasets/val.cache... 7808 images, 0 backgrounds\u001b[0m\n",
            "Plotting labels to runs/train/DR_all_epochs404/labels.jpg... \n",
            "Image sizes 960 train, 960 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/DR_all_epochs404\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/39      13.2G    0.03779     0.0625   0.009234        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240       0.78      0.608      0.687      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/39      13.2G    0.03404    0.05735   0.007332        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.816      0.646      0.727      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/39      13.2G    0.03134    0.05315   0.006002        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.832      0.674      0.758      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/39      13.2G    0.02949    0.05019   0.005194        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.852      0.689      0.777      0.543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/39      13.2G    0.02814    0.04778   0.004634        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.859      0.708      0.793      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/39      13.2G    0.02718     0.0459   0.004125        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240       0.87      0.715        0.8      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/39      13.2G    0.02641    0.04439   0.003805        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.872      0.726      0.809      0.582\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/39      13.2G    0.02589    0.04292   0.003566        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.877      0.732      0.813      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/39      13.2G    0.02531    0.04166   0.003359        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.876      0.739      0.818      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/39      13.2G    0.02481    0.04053   0.003173        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.883       0.74      0.821      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/39      13.2G    0.02437    0.03955   0.003005        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.883      0.744      0.822      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/39      13.2G    0.02402     0.0386   0.002882        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.884      0.747      0.823      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/39      13.2G    0.02364    0.03762   0.002765        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.886      0.747      0.824      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/39      13.2G    0.02323    0.03658   0.002571        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.885       0.75      0.825      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/39      13.2G    0.02298    0.03588   0.002498        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.886       0.75      0.825      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/39      13.2G    0.02258    0.03499   0.002376        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.885      0.752      0.826      0.606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/39      13.2G    0.02228    0.03418   0.002317        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.885      0.753      0.825      0.606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/39      13.2G    0.02201    0.03337   0.002224        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.886      0.753      0.826      0.606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/39      13.2G    0.02168     0.0326   0.002127        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.887      0.753      0.826      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/39      13.2G    0.02137    0.03171   0.002043        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.886      0.754      0.826      0.607\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/39      13.2G     0.0211     0.0309   0.001973        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.886      0.754      0.826      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/39      13.2G    0.02083    0.03014   0.001914        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.887      0.753      0.826      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/39      13.2G    0.02054    0.02946   0.001812        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.887      0.753      0.826      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/39      13.2G    0.02019    0.02861   0.001754        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.888      0.753      0.825      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/39      13.2G    0.01994    0.02786   0.001698        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.889      0.753      0.825      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/39      13.2G    0.01966    0.02697   0.001632        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.888      0.753      0.825      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/39      13.2G    0.01935    0.02616   0.001579        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.889      0.754      0.824      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/39      13.2G    0.01902    0.02539   0.001528        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.889      0.753      0.824      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/39      13.2G    0.01877    0.02464   0.001474        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240       0.89      0.753      0.823      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/39      13.2G    0.01841    0.02375   0.001402        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240       0.89      0.754      0.823      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/39      13.2G    0.01806    0.02288   0.001334        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240       0.89      0.753      0.822      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/39      13.2G    0.01773      0.022   0.001264        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.892      0.752      0.821      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/39      13.2G    0.01733     0.0211   0.001215        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.892       0.75       0.82      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      36/39      13.2G      0.017    0.02027   0.001146        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.892       0.75      0.819      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/39      13.2G    0.01665    0.01947   0.001099        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.891      0.749      0.817      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/39      13.2G    0.01627    0.01862    0.00105        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.891      0.749      0.816      0.608\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/39      13.2G    0.01586    0.01778   0.001008        139        960: 1\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.892      0.747      0.815      0.607\n",
            "\n",
            "37 epochs completed in 9.980 hours.\n",
            "Optimizer stripped from runs/train/DR_all_epochs404/weights/last.pt, 42.3MB\n",
            "Optimizer stripped from runs/train/DR_all_epochs404/weights/best.pt, 42.3MB\n",
            "\n",
            "Validating runs/train/DR_all_epochs404/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20865057 parameters, 0 gradients, 47.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       7808      69240      0.889      0.753      0.824      0.609\n",
            "                   car       7808      41601      0.926       0.84      0.913       0.74\n",
            "                   bus       7808       6288      0.901      0.792      0.848      0.655\n",
            "                 truck       7808       8160      0.875       0.74      0.805      0.616\n",
            "            pedestrian       7808      13191      0.855      0.642       0.73      0.426\n",
            "Results saved to \u001b[1mruns/train/DR_all_epochs404\u001b[0m\n",
            "CPU times: user 14min 22s, sys: 8min 54s, total: 23min 17s\n",
            "Wall time: 10h 1min 22s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%cd /home/kdw24739577/yolov5\n",
        "!python train.py --resume --img 960 --rect --batch 32 --epochs 40 --data /home/kdw24739577/yolov5/data/data.yaml --weights ./runs/train/DR_all_epochs_404/weights/last.pt --seed 300 --name DR_all_epochs40 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81dc63a3",
      "metadata": {
        "id": "81dc63a3"
      },
      "outputs": [],
      "source": [
        "!cp /home/kdw24739577/yolov5/runs/train/DR_all_epochs404/weights/best.pt /home/kdw24739577/gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdbdfb30",
      "metadata": {
        "id": "bdbdfb30",
        "outputId": "7c4b186e-ad8f-437e-8f08-3670b6ed9e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/kdw24739577/yolov5/runs/train\n",
            "DR_all_epochs40\t\t  T6040_W553015u_epochs402  rain_all_DC10500_NR60002\r\n",
            "DR_all_epochs402\t  T6040_W553015u_epochs403  rain_all_DC10500_NR60003\r\n",
            "DR_all_epochs403\t  T6040_W553015u_epochs404  rain_all_DC10500_NR60004\r\n",
            "DR_all_epochs404\t  T6040_W553015u_epochs405  rain_all_DC10500_NR60005\r\n",
            "T6040_W503515.tar.gz\t  T6040_W553015u_epochs406  rain_all_DC10500_NR60006\r\n",
            "T6040_W503515u_epochs40   T6040_W553015u_epochs407  rain_all_DC10500_NR60007\r\n",
            "T6040_W503515u_epochs402  rain_all_DC10500\t    result.tar.gz\r\n",
            "T6040_W503515u_epochs403  rain_all_DC10500.tar.gz\r\n",
            "T6040_W553015u_epochs40   rain_all_DC10500_NR6000\r\n"
          ]
        }
      ],
      "source": [
        "%cd /home/kdw24739577/yolov5/runs/train/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd8ccc3",
      "metadata": {
        "id": "1dd8ccc3",
        "outputId": "d0be72ed-96c5-47ec-e023-0d23ca51dd5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DR_all_epochs404/\n",
            "DR_all_epochs404/train_batch0.jpg\n",
            "DR_all_epochs404/val_batch2_pred.jpg\n",
            "DR_all_epochs404/hyp.yaml\n",
            "DR_all_epochs404/confusion_matrix.png\n",
            "DR_all_epochs404/PR_curve.png\n",
            "DR_all_epochs404/results.png\n",
            "DR_all_epochs404/events.out.tfevents.1670498706.instance-1.1706.0\n",
            "DR_all_epochs404/F1_curve.png\n",
            "DR_all_epochs404/P_curve.png\n",
            "DR_all_epochs404/labels_correlogram.jpg\n",
            "DR_all_epochs404/train_batch1.jpg\n",
            "DR_all_epochs404/results.csv\n",
            "DR_all_epochs404/val_batch1_labels.jpg\n",
            "DR_all_epochs404/weights/\n",
            "DR_all_epochs404/weights/last.pt\n",
            "DR_all_epochs404/weights/best.pt\n",
            "DR_all_epochs404/labels.jpg\n",
            "DR_all_epochs404/events.out.tfevents.1670495117.instance-1.1401.0\n",
            "DR_all_epochs404/train_batch2.jpg\n",
            "DR_all_epochs404/val_batch1_pred.jpg\n",
            "DR_all_epochs404/val_batch0_labels.jpg\n",
            "DR_all_epochs404/R_curve.png\n",
            "DR_all_epochs404/val_batch0_pred.jpg\n",
            "DR_all_epochs404/opt.yaml\n",
            "DR_all_epochs404/val_batch2_labels.jpg\n"
          ]
        }
      ],
      "source": [
        "!tar -zcvf DR_all.tar.gz DR_all_epochs404"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b518f9",
      "metadata": {
        "id": "e1b518f9"
      },
      "outputs": [],
      "source": [
        "!cp DR_all.tar.gz /home/kdw24739577/gdrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a05e6723",
      "metadata": {
        "id": "a05e6723"
      },
      "outputs": [],
      "source": [
        "df13 = df_val[(df_val['time']=='day') & (df_val['weather']=='sunny')]['val_path'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32fc9d94",
      "metadata": {
        "id": "32fc9d94"
      },
      "outputs": [],
      "source": [
        "with open('/home/kdw24739577/datasets/val.txt', 'w') as f: # val.txt에 파일 경로를 전부 적어줌\n",
        "  f.write('\\n'.join(df13)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4721dd",
      "metadata": {
        "id": "6b4721dd",
        "outputId": "0deef2d1-2080-4065-e9b4-6e69bb27eb86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/kdw24739577/yolov5\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/kdw24739577/yolov5/data/data.yaml, weights=['./runs/train/DR_all_epochs404/weights/best.pt'], batch_size=32, imgsz=960, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 🚀 v6.2-267-gbe348cc Python-3.9.13 torch-1.7.1+cu110 CUDA:0 (Tesla V100-SXM2-16GB, 16161MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20865057 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/kdw24739577/datasets/val... 2322 images, 0 backgrounds, 0 co\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/kdw24739577/datasets/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       2322      21268      0.889       0.77      0.837      0.633\n",
            "                   car       2322      13070      0.928      0.861      0.926      0.774\n",
            "                   bus       2322       1845      0.903      0.827      0.875      0.692\n",
            "                 truck       2322       3253      0.868      0.755      0.815      0.635\n",
            "            pedestrian       2322       3100      0.857      0.639      0.733      0.431\n",
            "Speed: 0.3ms pre-process, 2.9ms inference, 1.5ms NMS per image at shape (32, 3, 960, 960)\n",
            "Results saved to \u001b[1mruns/val/exp36\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd ~/yolov5\n",
        "!python val.py --weights ./runs/train/DR_all_epochs404/weights/best.pt --data data.yaml --img 960 --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d199f81c",
      "metadata": {
        "id": "d199f81c"
      },
      "outputs": [],
      "source": [
        "df13 = df_val[(df_val['time']=='day') & (df_val['weather']=='cloudy')]['val_path'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee4b79da",
      "metadata": {
        "id": "ee4b79da"
      },
      "outputs": [],
      "source": [
        "with open('/home/kdw24739577/datasets/val.txt', 'w') as f: # val.txt에 파일 경로를 전부 적어줌\n",
        "  f.write('\\n'.join(df13)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67d23b12",
      "metadata": {
        "id": "67d23b12",
        "outputId": "d08be000-4de2-4668-d4ae-d3aa11d7875e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/kdw24739577/yolov5/data/data.yaml, weights=['./runs/train/DR_all_epochs404/weights/best.pt'], batch_size=32, imgsz=960, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 🚀 v6.2-267-gbe348cc Python-3.9.13 torch-1.7.1+cu110 CUDA:0 (Tesla V100-SXM2-16GB, 16161MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20865057 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/kdw24739577/datasets/val... 1382 images, 0 backgrounds, 0 co\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/kdw24739577/datasets/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       1382      13674      0.894      0.764      0.827      0.625\n",
            "                   car       1382       7127      0.928      0.851      0.918      0.764\n",
            "                   bus       1382        774      0.885      0.815      0.847      0.673\n",
            "                 truck       1382       2816      0.899      0.743      0.818      0.624\n",
            "            pedestrian       1382       2957      0.865      0.646      0.726      0.441\n",
            "Speed: 0.3ms pre-process, 3.0ms inference, 1.9ms NMS per image at shape (32, 3, 960, 960)\n",
            "Results saved to \u001b[1mruns/val/exp37\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python val.py --weights ./runs/train/DR_all_epochs404/weights/best.pt --data data.yaml --img 960 --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c7e4da4",
      "metadata": {
        "id": "6c7e4da4"
      },
      "outputs": [],
      "source": [
        "df13 = df_val[(df_val['time']=='day') & (df_val['weather']=='rain')]['val_path'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6453445d",
      "metadata": {
        "id": "6453445d"
      },
      "outputs": [],
      "source": [
        "with open('/home/kdw24739577/datasets/val.txt', 'w') as f: # val.txt에 파일 경로를 전부 적어줌\n",
        "  f.write('\\n'.join(df13)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "316c3478",
      "metadata": {
        "id": "316c3478",
        "outputId": "b98d6cbd-b398-46ec-8197-cfa76d7ab21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/kdw24739577/yolov5/data/data.yaml, weights=['./runs/train/DR_all_epochs404/weights/best.pt'], batch_size=32, imgsz=960, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 🚀 v6.2-267-gbe348cc Python-3.9.13 torch-1.7.1+cu110 CUDA:0 (Tesla V100-SXM2-16GB, 16161MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20865057 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/kdw24739577/datasets/val... 601 images, 0 backgrounds, 0 cor\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/kdw24739577/datasets/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all        601       4753      0.901      0.736      0.815      0.615\n",
            "                   car        601       3280      0.936      0.836      0.916      0.752\n",
            "                   bus        601        441      0.912      0.828      0.889      0.733\n",
            "                 truck        601        634      0.898      0.667       0.77      0.581\n",
            "            pedestrian        601        398      0.856      0.613      0.684      0.394\n",
            "Speed: 0.7ms pre-process, 3.0ms inference, 1.9ms NMS per image at shape (32, 3, 960, 960)\n",
            "Results saved to \u001b[1mruns/val/exp38\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python val.py --weights ./runs/train/DR_all_epochs404/weights/best.pt --data data.yaml --img 960 --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "325c27d7",
      "metadata": {
        "id": "325c27d7"
      },
      "outputs": [],
      "source": [
        "df13 = df_val[((df_val['time'] == 'sunset')|(df_val['time'] == 'night'))&(df_val['weather'] == 'sunny')]['val_path'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "077e3f1c",
      "metadata": {
        "id": "077e3f1c"
      },
      "outputs": [],
      "source": [
        "with open('/home/kdw24739577/datasets/val.txt', 'w') as f: # val.txt에 파일 경로를 전부 적어줌\n",
        "  f.write('\\n'.join(df13)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c81623",
      "metadata": {
        "id": "53c81623",
        "outputId": "f0cfde4e-ddc7-4c2d-e153-416a304f6e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/kdw24739577/yolov5/data/data.yaml, weights=['./runs/train/DR_all_epochs404/weights/best.pt'], batch_size=32, imgsz=960, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 🚀 v6.2-267-gbe348cc Python-3.9.13 torch-1.7.1+cu110 CUDA:0 (Tesla V100-SXM2-16GB, 16161MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20865057 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/kdw24739577/datasets/val... 1318 images, 0 backgrounds, 0 co\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/kdw24739577/datasets/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       1318      11265      0.899       0.76       0.84      0.618\n",
            "                   car       1318       6890      0.943      0.831      0.914      0.731\n",
            "                   bus       1318        824      0.889      0.799      0.851      0.658\n",
            "                 truck       1318        702      0.876      0.757       0.83      0.633\n",
            "            pedestrian       1318       2849      0.887      0.653      0.765      0.451\n",
            "Speed: 0.2ms pre-process, 2.9ms inference, 1.6ms NMS per image at shape (32, 3, 960, 960)\n",
            "Results saved to \u001b[1mruns/val/exp39\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python val.py --weights ./runs/train/DR_all_epochs404/weights/best.pt --data data.yaml --img 960 --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db53e4f6",
      "metadata": {
        "id": "db53e4f6"
      },
      "outputs": [],
      "source": [
        "df13 = df_val[((df_val['time'] == 'sunset')|(df_val['time'] == 'night'))&(df_val['weather'] == 'cloudy')]['val_path'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "018de859",
      "metadata": {
        "id": "018de859"
      },
      "outputs": [],
      "source": [
        "with open('/home/kdw24739577/datasets/val.txt', 'w') as f: # val.txt에 파일 경로를 전부 적어줌\n",
        "  f.write('\\n'.join(df13)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0fdb860",
      "metadata": {
        "id": "b0fdb860",
        "outputId": "0b96f952-c154-4709-e616-d9c2c1bf73fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/kdw24739577/yolov5/data/data.yaml, weights=['./runs/train/DR_all_epochs404/weights/best.pt'], batch_size=32, imgsz=960, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 🚀 v6.2-267-gbe348cc Python-3.9.13 torch-1.7.1+cu110 CUDA:0 (Tesla V100-SXM2-16GB, 16161MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20865057 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/kdw24739577/datasets/val... 1174 images, 0 backgrounds, 0 co\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/kdw24739577/datasets/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       1174      10150      0.869      0.749      0.819       0.59\n",
            "                   car       1174       5983      0.913      0.834      0.909      0.708\n",
            "                   bus       1174        834      0.881      0.782      0.836      0.623\n",
            "                 truck       1174        472      0.834      0.718      0.786      0.597\n",
            "            pedestrian       1174       2861      0.848      0.661      0.745       0.43\n",
            "Speed: 0.2ms pre-process, 2.9ms inference, 1.9ms NMS per image at shape (32, 3, 960, 960)\n",
            "Results saved to \u001b[1mruns/val/exp40\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python val.py --weights ./runs/train/DR_all_epochs404/weights/best.pt --data data.yaml --img 960 --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a2b53c",
      "metadata": {
        "id": "75a2b53c"
      },
      "outputs": [],
      "source": [
        "df13 = df_val[((df_val['time'] == 'sunset')|(df_val['time'] == 'night'))&(df_val['weather'] == 'rain')]['val_path'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3a03784",
      "metadata": {
        "id": "d3a03784"
      },
      "outputs": [],
      "source": [
        "with open('/home/kdw24739577/datasets/val.txt', 'w') as f: # val.txt에 파일 경로를 전부 적어줌\n",
        "  f.write('\\n'.join(df13)+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a34e0969",
      "metadata": {
        "id": "a34e0969",
        "outputId": "73539001-c2e4-40c0-a830-0bee1c1f67a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/home/kdw24739577/yolov5/data/data.yaml, weights=['./runs/train/DR_all_epochs404/weights/best.pt'], batch_size=32, imgsz=960, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 🚀 v6.2-267-gbe348cc Python-3.9.13 torch-1.7.1+cu110 CUDA:0 (Tesla V100-SXM2-16GB, 16161MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 212 layers, 20865057 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/kdw24739577/datasets/val... 1011 images, 0 backgrounds, 0 co\u001b[0m\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/kdw24739577/datasets/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   \n",
            "                   all       1011       8130      0.844      0.676      0.749      0.513\n",
            "                   car       1011       5251       0.91      0.795      0.876      0.663\n",
            "                   bus       1011       1570      0.923       0.74      0.822      0.608\n",
            "                 truck       1011        283      0.757      0.636      0.682      0.466\n",
            "            pedestrian       1011       1026      0.788      0.532      0.617      0.315\n",
            "Speed: 0.3ms pre-process, 2.9ms inference, 1.7ms NMS per image at shape (32, 3, 960, 960)\n",
            "Results saved to \u001b[1mruns/val/exp41\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python val.py --weights ./runs/train/DR_all_epochs404/weights/best.pt --data data.yaml --img 960 --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bee478d",
      "metadata": {
        "id": "6bee478d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}